{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OptimizedDataGenerator4 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "import graphviz\n",
    "from qkeras import QDense, QActivation, quantized_bits, quantized_relu\n",
    "from plotting import *\n",
    "\n",
    "noGPU=False\n",
    "if noGPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// plotting code from google ai https://www.google.com/search?client=firefox-b-1-d&q=plot+tensorflow+model+history\n",
    "# then modified\n",
    "def plotModelHistory(history,modelNum = -999):\n",
    "    plt.subplot(211)\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'],label=\"Train\")\n",
    "    plt.plot(history.history['val_loss'],label=\"Validation\")\n",
    "    plt.title(f'Model {modelNum} loss and accuracy')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.subplot(212)\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['binary_accuracy'],label=\"Train\")\n",
    "    plt.plot(history.history['val_binary_accuracy'],label=\"Validation\")\n",
    "    # plt.title(f'Model {modelNum} accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir = \"./tf_records1000Daniel/tfrecords_validation/\"\n",
    "train_dir = \"./tf_records1000Daniel/tfrecords_train/\"\n",
    "x_feature_description: list = ['x_size','z_global','y_profile','x_profile','cluster', 'y_size', 'x_size', 'y_local']\n",
    "trainODG = OptimizedDataGenerator(tf_records_dir=train_dir,load_records=True, x_feature_description=x_feature_description)\n",
    "validationODG = OptimizedDataGenerator(tf_records_dir=validation_dir,load_records=True, x_feature_description=x_feature_description)\n",
    "# trainODG._parse_tfrecord_fn()\n",
    "## where do we tell it to use the z-global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(total_bits, int_bits):\n",
    "    \"\"\"\n",
    "    Build & compile your QKeras model with the given number of integer bits.\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    # inputs\n",
    "    input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "    input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "    input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "    input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "    x = tf.keras.layers.Concatenate()([input1, input2, input3, input4])\n",
    "\n",
    "    ## I want to try this with 1 int bit and 7 fractional\n",
    "    ## I want to try this with 0 int bit and 7 fractional\n",
    "    \n",
    "    # layer 1\n",
    "    x = QDense(\n",
    "        17,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "        ## adds sum of the activations squared to the loss function \n",
    "        #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        activation=quantized_relu(total_bits, int_bits),\n",
    "        name=\"q_relu1\"\n",
    "    )(x)\n",
    "\n",
    "    # layer 2 (example—you can tweak per‐layer bits)\n",
    "    x = QDense(\n",
    "        20,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "        ## adds sum of the activations squared to the loss function \n",
    "        #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        activation=quantized_relu(total_bits, int_bits),\n",
    "        name=\"q_relu2\"\n",
    "    )(x)\n",
    "\n",
    "    # layer 3\n",
    "    x = QDense(\n",
    "        9,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "        ## adds sum of the activations squared to the loss function \n",
    "        #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        activation=quantized_relu(total_bits, int_bits),\n",
    "        name=\"q_relu3\"\n",
    "    )(x)\n",
    "\n",
    "    # layer 4\n",
    "    x = QDense(\n",
    "        16,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "        ## adds sum of the activations squared to the loss function \n",
    "        #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        activation=quantized_relu(total_bits, int_bits),\n",
    "        name=\"q_relu4\"\n",
    "    )(x)\n",
    "\n",
    "    # layer 5\n",
    "    x = QDense(\n",
    "        8,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "        ## adds sum of the activations squared to the loss function \n",
    "        #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        activation=quantized_relu(total_bits, int_bits),\n",
    "        name=\"q_relu5\"\n",
    "    )(x)\n",
    "\n",
    "    # output\n",
    "    x = QDense(\n",
    "        1,\n",
    "        kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        bias_quantizer=quantized_bits(total_bits, int_bits, alpha=0.001),\n",
    "        #kernel_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "    )(x)\n",
    "    out = QActivation(\"smooth_sigmoid\")(x)\n",
    "    \n",
    "    m = tf.keras.Model(inputs=[input1, input2, input3, input4], outputs=out)\n",
    "    m.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_accuracy\"],\n",
    "        run_eagerly=True\n",
    "    )\n",
    "    return m\n",
    "\n",
    "models = {}\n",
    "\n",
    "# 1) define your sweep\n",
    "total_bits = [16]\n",
    "int_bits =   [8]\n",
    "\n",
    "# 2) containers for final metrics\n",
    "train_losses, val_losses = {}, {}\n",
    "train_accs,   val_accs   = {}, {}\n",
    "\n",
    "for i, val in enumerate(total_bits):\n",
    "    print(f\"\\n→ training model with {val} total bits and {int_bits[i]} integer bits\")\n",
    "    model = make_model(val, int_bits[i])\n",
    "    \n",
    "\n",
    "    name = f\"total: {val}, int: {int_bits[i]}\"\n",
    "    models[name] = model\n",
    "\n",
    "    hist  = model.fit(\n",
    "        x=trainODG,\n",
    "        validation_data=validationODG,\n",
    "        epochs=100        # you can shorten for quick experiments\n",
    "        #verbose=1\n",
    "    )\n",
    "    train_losses[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"] = hist.history[\"loss\"]\n",
    "    val_losses[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"] = hist.history[\"val_loss\"]\n",
    "\n",
    "    train_accs[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"] = hist.history[\"binary_accuracy\"]\n",
    "    val_accs[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"] = hist.history[\"val_binary_accuracy\"]\n",
    "\n",
    "\n",
    "plt.subplot(211)\n",
    "for i, val in enumerate(total_bits):\n",
    "    plt.plot(train_losses[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"], label=f\"train loss {int_bits[i]}, {val}\")\n",
    "    plt.plot(val_losses[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"], label=f\"val loss {int_bits[i]}, {val}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "# … your plotting calls …\n",
    "for i, val in enumerate(total_bits):\n",
    "    plt.plot(train_accs[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"], label=f\"train acc {int_bits[i]}, {val}\")\n",
    "    plt.plot(val_accs[f\"int: {int_bits[i]}, fractions: {val - int_bits[i] - 1}\"], label=f\"val acc {int_bits[i]}, {val}\")\n",
    "\n",
    "\n",
    "# place the legend to the right, outside the plot\n",
    "plt.legend(\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1.02, 1),      # x=1.02 = just to the right of the axes, y=1 = top\n",
    "    borderaxespad=0                # no padding between axes and legend\n",
    ")\n",
    "plt.tight_layout()    \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = {}\n",
    "print(len(models))\n",
    "for name, m in models.items():\n",
    "    loss, acc = m.evaluate(validationODG)\n",
    "    graph[name] = acc\n",
    "    print(acc)\n",
    "\n",
    "names = list(graph.keys())\n",
    "accuracies = list(graph.values())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(names, accuracies)\n",
    "\n",
    "# Add accuracy labels on top of each bar\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,   # x-position (center of bar)\n",
    "        bar.get_height(),                    # y-position (top of bar)\n",
    "        f\"{acc:.3f}\",                        # formatted accuracy\n",
    "        ha='center', va='bottom'             # align center, place just above bar\n",
    "    )\n",
    "\n",
    "plt.xlabel('Model (total_bits_int_bits)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy per Quantized Model')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_weights(models, per_layer=False, mode=\"stem\", include_bias=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
