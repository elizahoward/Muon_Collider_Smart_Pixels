{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6661b2ea",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b436c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:01:02.626901Z",
     "iopub.status.busy": "2026-01-04T17:01:02.626575Z",
     "iopub.status.idle": "2026-01-04T17:01:05.006733Z",
     "shell.execute_reply": "2026-01-04T17:01:05.006304Z"
    },
    "papermill": {
     "duration": 2.383509,
     "end_time": "2026-01-04T17:01:05.007645",
     "exception": false,
     "start_time": "2026-01-04T17:01:02.624136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 11:01:02.786703: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-04 11:01:02.789291: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-04 11:01:02.820661: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-04 11:01:02.820683: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-04 11:01:02.820705: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-04 11:01:02.826668: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-04 11:01:02.827066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 11:01:03.545168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'MuC_Smartpix_ML.Model_Classes.SmartPixModel'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from OptimizedDataGenerator4 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "noGPU=False\n",
    "if noGPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(\"\\nHIIIIIIIIIIIIIIIIII\\n\")\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "print(tf.test.is_gpu_available())\n",
    "\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "# import all the necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay, ExponentialDecay, CosineDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"/local/d1/smartpixML/filtering_models/shuffling_data/\") #TODO use the ODG from here\n",
    "import OptimizedDataGenerator4_data_shuffled_bigData as ODG2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "sys.path.append(\"../ryan\")\n",
    "import OptimizedDataGenerator4 as ODG\n",
    "\n",
    "\n",
    "sys.path.append(str(Path.cwd().parents[0]))\n",
    "\n",
    "from MuC_Smartpix_ML.Model_Classes import SmartPixModel\n",
    "print(SmartPixModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af94200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:01:05.011839Z",
     "iopub.status.busy": "2026-01-04T17:01:05.011466Z",
     "iopub.status.idle": "2026-01-04T17:01:05.031502Z",
     "shell.execute_reply": "2026-01-04T17:01:05.031137Z"
    },
    "papermill": {
     "duration": 0.022922,
     "end_time": "2026-01-04T17:01:05.032272",
     "exception": false,
     "start_time": "2026-01-04T17:01:05.009350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model1(SmartPixModel):\n",
    "    def __init__(self,\n",
    "            tfRecordFolder: str = \"/local/d1/smartpixML/filtering_models/shuffling_data/all_batches_shuffled_bigData_try2/filtering_records16384_data_shuffled_single_bigData/\",\n",
    "            nBits: list = None, # just for fractional bits, integer bits\n",
    "                                ## number of bits is the number of bits for each quantized model and then\n",
    "                                ## run training should make one model for each bit size\n",
    "            loadModel: bool = False,\n",
    "            modelPath: str = None, # Only include if you are loading a model\n",
    "                        # dropout_rate: float = 0.1,\n",
    "            initial_lr: float = 1e-3,\n",
    "            end_lr: float = 1e-4,\n",
    "            power: int = 2,\n",
    "            bit_configs = [(16, 0), (8, 0), (6, 0), (4, 0), (3, 0), (2, 0)]  # Test 16, 8, 6, 4, 3, and 2-bit quantization\n",
    "            ): \n",
    "        self.tfRecordFolder = tfRecordFolder\n",
    "        self.modelName = \"Model1\" # for other models, e.g., Model 1, Model 2, etc.\n",
    "        # self.model = None\n",
    "        self.histories = {}\n",
    "        self.models = {\"Unquantized\": None}\n",
    "        self.bit_configs = bit_configs\n",
    "        for total_bits, int_bits in self.bit_configs:\n",
    "            config_name = f\"quantized_{total_bits}w{int_bits}i\"\n",
    "            self.models[config_name] = None\n",
    "        # self.quantized_model = None\n",
    "        self.hyperparameterModel = None\n",
    "        self.training_generator = None\n",
    "        self.validation_generator = None\n",
    "        self.x_feature_description: list = ['z_global','x_size', 'y_size', 'y_local']\n",
    "        # Learning rate parameters\n",
    "        self.initial_lr = initial_lr\n",
    "        self.end_lr = end_lr\n",
    "        self.power = power\n",
    "        return\n",
    "     \n",
    "    def makeUnquantizedModel(self):\n",
    "        ## here i will be making a 4-layer neural network \n",
    "        ## Model 1: z-global, x size, y size, y local\n",
    "\n",
    "\n",
    "        ## define the inputs\n",
    "        input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "        input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "        input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "        input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "\n",
    "        ## concatenate the inputs into one layer\n",
    "        inputList = [input1, input2, input3, input4]\n",
    "        inputs = tf.keras.layers.Concatenate()(inputList)\n",
    "\n",
    "\n",
    "        ## here i will add the layers \n",
    "\n",
    "        stack1 = tf.keras.layers.Dense(17,activation='relu')(inputs)\n",
    "        stack2 = tf.keras.layers.Dense(20, activation='relu')(stack1)\n",
    "        stack3 = tf.keras.layers.Dense(9, activation='relu')(stack2)\n",
    "        stack4 = tf.keras.layers.Dense(16, activation='relu')(stack3)\n",
    "        stack5 = tf.keras.layers.Dense(18, activation='relu')(stack4)\n",
    "        output = tf.keras.layers.Dense(1,activation='sigmoid')(stack5)\n",
    "\n",
    "        self.models[\"Unquantized\"] = tf.keras.Model(inputs=inputList, outputs=output)\n",
    "\n",
    "\n",
    "    def makeUnquatizedModelHyperParameterTuning(self):\n",
    "        def model_builder(hp):\n",
    "            # ── B) Architecture hyperparams ──────────────────────────────────────────\n",
    "            # separately tune rows and cols\n",
    "\n",
    "            row1nodes      = hp.Int(\"1\",   1, 30, step=1)\n",
    "            row2nodes      = hp.Int(\"2\",   1, 30, step=1)\n",
    "            row3nodes      = hp.Int(\"3\",   1, 30, step=1)\n",
    "            row4nodes      = hp.Int(\"4\",   1, 30, step=1)\n",
    "            row5nodes      = hp.Int(\"5\",   1, 30, step=1)\n",
    "\n",
    "\n",
    "\n",
    "            input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "            input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "            input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "            input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "\n",
    "            ## concatenate the inputs into one layer\n",
    "            inputList = [input1, input2, input3, input4]\n",
    "            inputs = tf.keras.layers.Concatenate()(inputList)\n",
    "\n",
    "\n",
    "            ## here i will add the layers \n",
    "\n",
    "            # layer 1\n",
    "            x = tf.keras.layers.Dense(row1nodes,activation='relu')(inputs)\n",
    "            x = tf.keras.layers.Dense(row2nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row3nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row4nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row5nodes, activation='relu')(x)\n",
    "            output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputList, outputs=output)\n",
    "\n",
    "            model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"binary_accuracy\"],\n",
    "            run_eagerly  = True \n",
    "            )\n",
    "            return model\n",
    "\n",
    "        tuner = kt.RandomSearch(\n",
    "        model_builder, \n",
    "        objective           = \"val_binary_accuracy\",\n",
    "        max_trials          = 120,\n",
    "        executions_per_trial = 2,\n",
    "        project_name        = \"hp_search_1_30\"\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            self.training_generator,\n",
    "            validation_data = self.validation_generator,\n",
    "            epochs          = 110,\n",
    "            callbacks       = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def makeUnquatizedModelHyperParameterTuning2(self):\n",
    "        def model_builder(hp):\n",
    "            # ── B) Architecture hyperparams ──────────────────────────────────────────\n",
    "            # separately tune rows and cols\n",
    "\n",
    "            row1nodes      = hp.Int(\"1\",   1, 30, step=1)\n",
    "            row2nodes      = 16\n",
    "            row3nodes      = 15\n",
    "            row4nodes      = 26\n",
    "            row5nodes      = 12\n",
    "\n",
    "\n",
    "\n",
    "            input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "            input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "            input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "            input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "\n",
    "            ## concatenate the inputs into one layer\n",
    "            inputList = [input1, input2, input3, input4]\n",
    "            inputs = tf.keras.layers.Concatenate()(inputList)\n",
    "\n",
    "\n",
    "            ## here i will add the layers \n",
    "\n",
    "            # layer 1\n",
    "            x = tf.keras.layers.Dense(row1nodes,activation='relu')(inputs)\n",
    "            x = tf.keras.layers.Dense(row2nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row3nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row4nodes, activation='relu')(x)\n",
    "            x = tf.keras.layers.Dense(row5nodes, activation='relu')(x)\n",
    "            output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputList, outputs=output)\n",
    "\n",
    "            model.compile(\n",
    "            optimizer=\"adam\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"binary_accuracy\"],\n",
    "            run_eagerly  = True \n",
    "            )\n",
    "            return model\n",
    "\n",
    "        tuner = kt.RandomSearch(\n",
    "        model_builder, \n",
    "        objective           = \"val_binary_accuracy\",\n",
    "        max_trials          = 120,\n",
    "        executions_per_trial = 2,\n",
    "        project_name        = \"hp_search_1_30_row_1\"\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            self.training_generator,\n",
    "            validation_data = self.validation_generator,\n",
    "            epochs          = 110,\n",
    "            callbacks       = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "     \n",
    "\n",
    "\n",
    "    def makeQuantizedModel(self):\n",
    "        for total_bits, int_bits in self.bit_configs:\n",
    "            config_name = f\"quantized_{total_bits}w{int_bits}i\"\n",
    "        \n",
    "        \n",
    "            print(f\"Building {config_name} model...\")\n",
    "            self.makeQuantizedModel_withBits(total_bits=total_bits,int_bits=int_bits)\n",
    "\n",
    "    def makeQuantizedModel_withBits(self, total_bits = 8,int_bits =0):\n",
    "        \"\"\"\n",
    "        Build & compile your QKeras model with the given number of integer bits.\n",
    "        \"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        # inputs\n",
    "        input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "        input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "        input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "        input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "        x = tf.keras.layers.Concatenate()([input1, input2, input3, input4])\n",
    "\n",
    "        ## I want to try this with 1 int bit and 7 fractional\n",
    "        ## I want to try this with 0 int bit and 7 fractional\n",
    "        \n",
    "        # layer 1\n",
    "        x = QDense(\n",
    "            17,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "            ## adds sum of the activations squared to the loss function \n",
    "            #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        x = QActivation(\n",
    "            activation=quantized_relu(total_bits, int_bits),\n",
    "            name=\"q_relu1\"\n",
    "        )(x)\n",
    "\n",
    "        # layer 2 (example—you can tweak per‐layer bits)\n",
    "        x = QDense(\n",
    "            20,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "            ## adds sum of the activations squared to the loss function \n",
    "            #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        x = QActivation(\n",
    "            activation=quantized_relu(total_bits, int_bits),\n",
    "            name=\"q_relu2\"\n",
    "        )(x)\n",
    "\n",
    "        # layer 3\n",
    "        x = QDense(\n",
    "            9,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "            ## adds sum of the activations squared to the loss function \n",
    "            #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        x = QActivation(\n",
    "            activation=quantized_relu(total_bits, int_bits),\n",
    "            name=\"q_relu3\"\n",
    "        )(x)\n",
    "\n",
    "        # layer 4\n",
    "        x = QDense(\n",
    "            16,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "            ## adds sum of the activations squared to the loss function \n",
    "            #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        x = QActivation(\n",
    "            activation=quantized_relu(total_bits, int_bits),\n",
    "            name=\"q_relu4\"\n",
    "        )(x)\n",
    "\n",
    "        # layer 5\n",
    "        x = QDense(\n",
    "            8,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L1L2(0.0001),\n",
    "            ## adds sum of the activations squared to the loss function \n",
    "            #activity_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        x = QActivation(\n",
    "            activation=quantized_relu(total_bits, int_bits),\n",
    "            name=\"q_relu5\"\n",
    "        )(x)\n",
    "\n",
    "        # output\n",
    "        x = QDense(\n",
    "            1,\n",
    "            kernel_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            bias_quantizer=quantized_bits(total_bits, int_bits, alpha=1),\n",
    "            #kernel_regularizer=tf.keras.regularizers.L2(0.0001),\n",
    "        )(x)\n",
    "        out = QActivation(\"smooth_sigmoid\")(x)\n",
    "        config_name = f\"quantized_{total_bits}w{int_bits}i\"\n",
    "        self.models[config_name] = tf.keras.Model(inputs=[input1, input2, input3, input4], outputs=out)\n",
    "\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def runHyperparameterTuning(self):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method.\")\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844f43ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T17:01:05.035732Z",
     "iopub.status.busy": "2026-01-04T17:01:05.035408Z",
     "iopub.status.idle": "2026-01-05T13:56:01.929382Z",
     "shell.execute_reply": "2026-01-05T13:56:01.928779Z"
    },
    "papermill": {
     "duration": 75297.910007,
     "end_time": "2026-01-05T13:56:02.943653",
     "exception": false,
     "start_time": "2026-01-04T17:01:05.033646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 Complete [00h 47m 50s]\n",
      "val_binary_accuracy: 0.8791026473045349\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.8798604011535645\n",
      "Total elapsed time: 20h 54m 57s\n"
     ]
    }
   ],
   "source": [
    "m1 = Model1()                 # your subclass\n",
    "\n",
    "m1.loadTfRecords()            # <-- IMPORTANT: load training/validation generators\n",
    "\n",
    "m1.makeUnquatizedModelHyperParameterTuning2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b107390",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a00a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-05T13:56:02.948455Z",
     "iopub.status.busy": "2026-01-05T13:56:02.948218Z",
     "iopub.status.idle": "2026-01-05T13:56:03.308557Z",
     "shell.execute_reply": "2026-01-05T13:56:03.307918Z"
    },
    "papermill": {
     "duration": 0.363389,
     "end_time": "2026-01-05T13:56:03.309282",
     "exception": true,
     "start_time": "2026-01-05T13:56:02.945893",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m hp_values \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m r1 \u001b[38;5;241m=\u001b[39m hp_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mhp_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     43\u001b[0m r3 \u001b[38;5;241m=\u001b[39m hp_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m r4 \u001b[38;5;241m=\u001b[39m hp_values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: '2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "base_dir = \"/home/ryanmichaud/common_repo/Muon_Collider_Smart_Pixels/ryan/hp_search_1_30_row_1\"\n",
    "\n",
    "results = []\n",
    "\n",
    "# helper: builds a model with these layer widths and counts params\n",
    "def count_params_from_widths(r1, r2, r3, r4, r5):\n",
    "    input1 = tf.keras.layers.Input(shape=(1,))\n",
    "    input2 = tf.keras.layers.Input(shape=(1,))\n",
    "    input3 = tf.keras.layers.Input(shape=(1,))\n",
    "    input4 = tf.keras.layers.Input(shape=(1,))\n",
    "    inputs = tf.keras.layers.Concatenate()([input1, input2, input3, input4])\n",
    "\n",
    "    x = tf.keras.layers.Dense(r1, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(r2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r3, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r4, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r5, activation='relu')(x)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model([input1,input2,input3,input4], out)\n",
    "    return model.count_params()\n",
    "\n",
    "# loop through all trial folders\n",
    "for i in range(1, 120):\n",
    "    trial_folder = os.path.join(base_dir, f\"trial_{i:003d}\")\n",
    "    trial_json = os.path.join(trial_folder, \"trial.json\")\n",
    "\n",
    "    if not os.path.exists(trial_json):\n",
    "        continue\n",
    "\n",
    "    with open(trial_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    hp_values = data[\"hyperparameters\"][\"values\"]\n",
    "    r1 = hp_values[\"1\"]\n",
    "    r2 = hp_values[\"2\"]\n",
    "    r3 = hp_values[\"3\"]\n",
    "    r4 = hp_values[\"4\"]\n",
    "    r5 = hp_values[\"5\"]\n",
    "\n",
    "    val_acc = data[\"metrics\"][\"metrics\"][\"val_binary_accuracy\"][\"observations\"][0][\"value\"][0]\n",
    "\n",
    "    # compute number of parameters\n",
    "    total_params = count_params_from_widths(r1, r2, r3, r4, r5)\n",
    "\n",
    "    results.append({\n",
    "        \"trial\": i,\n",
    "        \"row1\": r1,\n",
    "        \"row2\": r2,\n",
    "        \"row3\": r3,\n",
    "        \"row4\": r4,\n",
    "        \"row5\": r5,\n",
    "        \"params\": total_params,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.head())\n",
    "\n",
    "# --- PLOT PARAM COUNT VS ACCURACY ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df[\"params\"], df[\"val_accuracy\"], alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Total Number of Parameters\")\n",
    "plt.ylabel(\"Validation Binary Accuracy\")\n",
    "plt.title(\"Model Size vs Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3df578",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "base_dir = \"/home/ryanmichaud/common_repo/Muon_Collider_Smart_Pixels/ryan/new_hyperparam_search\"\n",
    "\n",
    "results = []\n",
    "\n",
    "# helper: builds a model with these layer widths and counts params\n",
    "def count_params_from_widths(r1, r2, r3, r4, r5):\n",
    "    input1 = tf.keras.layers.Input(shape=(1,))\n",
    "    input2 = tf.keras.layers.Input(shape=(1,))\n",
    "    input3 = tf.keras.layers.Input(shape=(1,))\n",
    "    input4 = tf.keras.layers.Input(shape=(1,))\n",
    "    inputs = tf.keras.layers.Concatenate()([input1, input2, input3, input4])\n",
    "\n",
    "    x = tf.keras.layers.Dense(r1, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(r2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r3, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r4, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(r5, activation='relu')(x)\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model([input1,input2,input3,input4], out)\n",
    "    return model.count_params()\n",
    "\n",
    "# loop through all trial folders\n",
    "for i in range(1, 120):\n",
    "    trial_folder = os.path.join(base_dir, f\"trial_{i:003d}\")\n",
    "    trial_json = os.path.join(trial_folder, \"trial.json\")\n",
    "\n",
    "    if not os.path.exists(trial_json):\n",
    "        continue\n",
    "\n",
    "    with open(trial_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    hp_values = data[\"hyperparameters\"][\"values\"]\n",
    "    r1 = hp_values[\"1\"]\n",
    "    r2 = hp_values[\"2\"]\n",
    "    r3 = hp_values[\"3\"]\n",
    "    r4 = hp_values[\"4\"]\n",
    "    r5 = hp_values[\"5\"]\n",
    "\n",
    "    val_acc = data[\"metrics\"][\"metrics\"][\"val_loss\"][\"observations\"][0][\"value\"][0]\n",
    "\n",
    "    # compute number of parameters\n",
    "    total_params = count_params_from_widths(r1, r2, r3, r4, r5)\n",
    "\n",
    "    results.append({\n",
    "        \"trial\": i,\n",
    "        \"row1\": r1,\n",
    "        \"row2\": r2,\n",
    "        \"row3\": r3,\n",
    "        \"row4\": r4,\n",
    "        \"row5\": r5,\n",
    "        \"params\": total_params,\n",
    "        \"val_loss\": val_acc\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.head())\n",
    "\n",
    "# --- PLOT PARAM COUNT VS ACCURACY ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(df[\"params\"], df[\"val_loss\"], alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Total Number of Parameters\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.title(\"Model Size vs Validation Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj_qkeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 75303.98812,
   "end_time": "2026-01-05T13:56:05.908749",
   "environment_variables": {},
   "exception": true,
   "input_path": "hyperparam.ipynb",
   "output_path": "results2.ipynb",
   "parameters": {},
   "start_time": "2026-01-04T17:01:01.920629",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}