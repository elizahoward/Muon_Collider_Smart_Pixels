{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OptimizedDataGenerator4 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "noGPU=False\n",
    "if noGPU:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(\"\\nHIIIIIIIIIIIIIIIIII\\n\")\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "print(tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// plotting code from google ai https://www.google.com/search?client=firefox-b-1-d&q=plot+tensorflow+model+history\n",
    "# then modified\n",
    "def plotModelHistory(history,modelNum = -999):\n",
    "    plt.subplot(211)\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'],label=\"Train\")\n",
    "    plt.plot(history.history['val_loss'],label=\"Validation\")\n",
    "    plt.title(f'Model {modelNum} loss and accuracy')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.subplot(212)\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['binary_accuracy'],label=\"Train\")\n",
    "    plt.plot(history.history['val_binary_accuracy'],label=\"Validation\")\n",
    "    # plt.title(f'Model {modelNum} accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dir = \"./tf_records1000Daniel/tfrecords_validation/\"\n",
    "train_dir = \"./tf_records1000Daniel/tfrecords_train/\"\n",
    "x_feature_description: list = ['x_size','z_global','y_profile','x_profile','cluster', 'y_size', 'x_size', 'y_local']\n",
    "trainODG = OptimizedDataGenerator(tf_records_dir=train_dir,load_records=True, x_feature_description=x_feature_description)\n",
    "validationODG = OptimizedDataGenerator(tf_records_dir=validation_dir,load_records=True, x_feature_description=x_feature_description)\n",
    "# trainODG._parse_tfrecord_fn()\n",
    "## where do we tell it to use the z-global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETER SEARCH\n",
    "from qkeras import QDense, QActivation, quantized_bits, quantized_relu\n",
    "\n",
    "def model_builder(hp):\n",
    "\n",
    "    # ── B) Architecture hyperparams ──────────────────────────────────────────\n",
    "    # separately tune rows and cols\n",
    "\n",
    "    row1nodes      = hp.Int(\"1\",   10, 200, step=10)\n",
    "    row2nodes      = hp.Int(\"2\",   10, 200, step=10)\n",
    "    row3nodes      = hp.Int(\"3\",   10, 200, step=10)\n",
    "    row4nodes      = hp.Int(\"4\",   10, 200, step=10)\n",
    "    row5nodes      = hp.Int(\"5\",   10, 200, step=10)\n",
    "\n",
    "\n",
    "\n",
    "    input1 = tf.keras.layers.Input(shape=(1,), name=\"z_global\")\n",
    "    input2 = tf.keras.layers.Input(shape=(1,), name=\"x_size\")\n",
    "    input3 = tf.keras.layers.Input(shape=(1,), name=\"y_size\")\n",
    "    input4 = tf.keras.layers.Input(shape=(1,), name=\"y_local\")\n",
    "\n",
    "    ## concatenate the inputs into one layer\n",
    "    inputList = [input1, input2, input3, input4]\n",
    "    inputs = tf.keras.layers.Concatenate()(inputList)\n",
    "\n",
    "\n",
    "    ## here i will add the layers \n",
    "\n",
    "    # layer 1\n",
    "    x = tf.keras.layers.Dense(row1nodes,activation='relu')(inputs)\n",
    "    x = tf.keras.layers.Dense(row2nodes, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(row3nodes, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(row4nodes, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(row5nodes, activation='relu')(x)\n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputList, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    run_eagerly  = True \n",
    "    )\n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective           = \"val_binary_accuracy\",\n",
    "    max_trials          = 120,\n",
    "    executions_per_trial = 2,\n",
    "    project_name        = \"new_hyperparam_search\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tuner.search(\n",
    "    trainODG,\n",
    "    validation_data = validationODG,\n",
    "    epochs          = 110,\n",
    "    callbacks       = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
