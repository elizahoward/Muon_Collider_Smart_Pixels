{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74916fd-e541-44b7-81dc-7fbb987d5141",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Vivado - 4bit toy network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d694a0-8942-41bf-ad4a-c65f08e9aabe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa5b3422-99a8-460a-9771-72bffd11f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_HLS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b218c-bce1-4f1f-9259-cee4e46332bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings on the ASIC-group servers\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff03fd9-4e69-4d76-9579-dc5b77cc256d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, layers, models\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import hls4ml\n",
    "#import kerop\n",
    "\n",
    "import pyaml\n",
    "\n",
    "from typing import Union, List, Tuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca37c3-f930-40dd-bcc6-add8f01be09f",
   "metadata": {},
   "source": [
    "## Create qkeras model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48cdd991-0ca2-4d44-a541-82d52fe79a90",
   "metadata": {},
   "source": [
    "# We may remove this\n",
    "\n",
    "# custom loss function\n",
    "maxval = 1e9\n",
    "minval = 1e-9\n",
    "\n",
    "def custom_loss(y, p):\n",
    "    \n",
    "    mu = p[:, 0:8:2]\n",
    "    \n",
    "    # creating each matrix element in 4x4\n",
    "    Mdia = minval + tf.math.maximum(p[:, 1:8:2], 0)\n",
    "    Mcov = p[:,8:]\n",
    "    \n",
    "    # placeholder zero element\n",
    "    zeros = tf.zeros_like(Mdia[:,0])\n",
    "    \n",
    "    # assembles scale_tril matrix\n",
    "    row1 = tf.stack([Mdia[:,0],zeros,zeros,zeros])\n",
    "    row2 = tf.stack([Mcov[:,0],Mdia[:,1],zeros,zeros])\n",
    "    row3 = tf.stack([Mcov[:,1],Mcov[:,2],Mdia[:,2],zeros])\n",
    "    row4 = tf.stack([Mcov[:,3],Mcov[:,4],Mcov[:,5],Mdia[:,3]])\n",
    "\n",
    "    scale_tril = tf.transpose(tf.stack([row1,row2,row3,row4]),perm=[2,0,1])\n",
    "\n",
    "    dist = tfp.distributions.MultivariateNormalTriL(loc = mu, scale_tril = scale_tril) \n",
    "    \n",
    "    likelihood = dist.prob(y)  \n",
    "    likelihood = tf.clip_by_value(likelihood,minval,maxval)\n",
    "\n",
    "    NLL = -1*tf.math.log(likelihood)\n",
    "    \n",
    "    return tf.keras.backend.sum(NLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be561610-0fc1-46c3-93cf-db08ff44d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructs model\n",
    "# model has 5 separate branches for x, y, cotA, cotB, covariance predictions\n",
    "\n",
    "def var_network(var, hidden=10, output=2):\n",
    "    var = Flatten()(var)\n",
    "    var = QDense(\n",
    "        hidden,\n",
    "        kernel_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        activity_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "    )(var)\n",
    "    var = QActivation(\"quantized_tanh(8, 0, 1)\")(var)\n",
    "    var = QDense(\n",
    "        hidden,\n",
    "        kernel_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        activity_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "    )(var)\n",
    "    var = QActivation(\"quantized_tanh(8, 0, 1)\")(var)\n",
    "    return QDense(\n",
    "        output,\n",
    "        kernel_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(8, 1, alpha=1),\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "    )(var)\n",
    "\n",
    "def conv_network(var, kernel_size=3):\n",
    "    var = QSeparableConv2D(\n",
    "        5,kernel_size,\n",
    "        depthwise_quantizer=quantized_bits(4, 1, 1, alpha=1),\n",
    "        pointwise_quantizer=quantized_bits(4, 1, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(4, 1, alpha=1),\n",
    "        depthwise_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        pointwise_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        activity_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "    )(var)\n",
    "    var = QActivation(\"quantized_tanh(4, 0, 1)\")(var)\n",
    "    var = QSeparableConv2D(\n",
    "        5,kernel_size,\n",
    "        depthwise_quantizer=quantized_bits(4, 1, 1, alpha=1),\n",
    "        pointwise_quantizer=quantized_bits(4, 1, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(4, 1, alpha=1),\n",
    "        depthwise_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        pointwise_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        activity_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "    )(var)\n",
    "    var = QActivation(\"quantized_tanh(4, 0, 1)\")(var)\n",
    "    var = QConv2D(\n",
    "        5,1,\n",
    "        kernel_quantizer=quantized_bits(4, 1, alpha=1),\n",
    "        bias_quantizer=quantized_bits(4, 1, alpha=1),\n",
    "        kernel_regularizer=tf.keras.regularizers.L1L2(0.01),\n",
    "        activity_regularizer=tf.keras.regularizers.L2(0.01),\n",
    "    )(var)\n",
    "    var = QActivation(\"quantized_tanh(4, 0, 1)\")(var)    \n",
    "    return var\n",
    "\n",
    "def CreateModel(shape):\n",
    "    # Generate the same random values\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    x_base = x_in = Input(shape)\n",
    "    stack = conv_network(x_base)\n",
    "    stack = AveragePooling2D(\n",
    "        pool_size=(2, 2), \n",
    "        strides=None, \n",
    "        padding=\"valid\", \n",
    "        data_format=None,        \n",
    "    )(stack)\n",
    "    stack = QActivation(\"quantized_bits(8, 1, alpha=1)\")(stack)\n",
    "    stack = var_network(stack, hidden=16, output=14)\n",
    "    model = Model(inputs=x_in, outputs=stack)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a72da-ac08-403e-b1a0-bcebe53a3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiles model\n",
    "# loss = custom_loss\n",
    "model=CreateModel((13,21,20))#train_3Dx.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223b492-ca78-4bb1-9389-644a095e6035",
   "metadata": {},
   "source": [
    "## Show weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ee0dd-6caf-4524-9f64-7ba6cd9c4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the weights on console\n",
    "N_WEIGHTS = 10\n",
    "\n",
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "weights = model.get_weights()\n",
    "for i, w in enumerate(weights):\n",
    "    print(f\"Layer {i}:\")\n",
    "    print(w.flatten()[:N_WEIGHTS])\n",
    "    print(\"-----------\")\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041e0a7-8be7-43ee-93de-716ca2391be9",
   "metadata": {},
   "source": [
    "## Show model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1962999-bbc5-4e2a-9da5-0d6b91c474a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='vivado_model.png', show_shapes=True, show_layer_names=True, expand_nested=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6831aa7-206a-4735-961f-6f233f5e8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_qstats(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e5bb3-cfbe-45e5-92ca-a312d4b230c6",
   "metadata": {},
   "source": [
    "## Configure hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62ee5a-b7b8-4d57-b49d-a4e099b3ac38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    model, \n",
    "    granularity='name',\n",
    "    default_precision='fixed<16,3>',\n",
    "    #default_precision='fixed<17,7>',\n",
    ")\n",
    "config['LayerName']['input_1']['Precision']['result'] = 'fixed<4,1>'\n",
    "#config['LayerName']['q_dense_2']['Precision']['result'] = 'fixed<25,9>'\n",
    "#config['LayerName']['q_dense_2']['Precision']['accum'] = 'fixed<25,9>'\n",
    "#config['LayerName']['q_dense_2_linear']['Precision']['result'] = 'fixed<25,9>'\n",
    "#config['LayerName']['q_dense_2']['Precision']['result'] = 'fixed<19,9>'\n",
    "#config['LayerName']['q_dense_2']['Precision']['accum'] = 'fixed<19,9>'\n",
    "#config['LayerName']['q_dense_2_linear']['Precision']['result'] = 'fixed<19,9>'\n",
    "\n",
    "# LineBuffer produces smaller implementations (Phil)\n",
    "# Encoded    may produce larger implementations (Vladimir)\n",
    "#            may be deprecated\n",
    "config['Model']['ConvImplementation'] = 'Encoded'\n",
    "#config['Model']['ConvImplementation'] = 'LineBuffer' # Default\n",
    "\n",
    "config['Model']['Strategy'] = 'Latency'\n",
    "#config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "# Don't need this...\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, \n",
    "    hls_config=config, \n",
    "    output_dir='noslice_vivado_hls4ml_prj', \n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    #part='xc7z020clg400-1', \n",
    "    #io_type=\"io_parallel\",\n",
    "    io_type=\"io_stream\",\n",
    ")\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752fc96-46de-48c8-9127-61251fd5bb0c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(pyaml.dump(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337fd580-766d-4f4a-8be7-096114ab8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "hconfig = deepcopy(config)\n",
    "hconfig['LayerName']['input_1']['Precision']['result'] = 'fixed<4,1>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe843c-2007-4285-bb6d-aaab2f4c1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyaml.dump(hconfig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfb700-10ec-4ac3-8c4d-0238edf15243",
   "metadata": {},
   "source": [
    "## Run qkeras and hls4ml simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c929e0-4690-4558-87d4-b74cdd02c9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set a seed to have the same input traces on every run\n",
    "np.random.seed(42)\n",
    "\n",
    "toy_data = quantized_bits(4, 0, alpha=1)(np.random.rand(10000,13,21,20)).numpy()\n",
    "\n",
    "# Enable tracing for all of the layers\n",
    "for layer in hconfig['LayerName'].keys():\n",
    "    print('Enable tracing for layer:', layer)\n",
    "    hconfig['LayerName'][layer]['Trace'] = True\n",
    "\n",
    "hmodel = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=hconfig,\n",
    "    output_dir='noslice_hls4ml_vivado_trace_prj',\n",
    "    part='xcu250-figd2104-2L-e',\n",
    "    #io_type=\"io_parallel\",\n",
    "    io_type=\"io_stream\",\n",
    ") # ZCU216, engineering sample\n",
    "#part='xczu49dr-ffvf1760-2-e') # ZCU216\n",
    "hmodel.compile()\n",
    "\n",
    "# Run tracing on the test set for the hls4ml model (fixed-point precision) \n",
    "hls4ml_pred, hls4ml_trace = hmodel.trace(toy_data)\n",
    "\n",
    "# Run tracing on a portion of the test set for the Keras model (floating-point precision)\n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd592b-38f6-4d2e-b903-ead511b12a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inputs and expected outputs for further debugging\n",
    "with open('noslice_hls4ml_vivado_trace_prj/tb_data/vivado_inputs.dat', 'w') as f:\n",
    "    f.write(' '.join(map(str, toy_data[0].flatten())))\n",
    "with open('noslice_hls4ml_vivado_trace_prj/tb_data/vivado_outputs.dat', 'w') as f:\n",
    "    f.write(' '.join(map(str, keras_trace['q_dense_2'][0].flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c658a3-8bcf-44df-8c9d-a9a6a762b4d2",
   "metadata": {},
   "source": [
    "## Show traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635be40-5546-4ad9-bea9-64e73321918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the traces on console\n",
    "N_ELEMENTS=5\n",
    "\n",
    "# Backup print options\n",
    "bkp_threshold = np.get_printoptions()['threshold']\n",
    "bkp_linewidth = np.get_printoptions()['linewidth']\n",
    "\n",
    "# Set print options\n",
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "\n",
    "print('input', toy_data[0][0][0][:20])\n",
    "for key in hls4ml_trace.keys():\n",
    "    print('-------')\n",
    "    print(key, hls4ml_trace[key].shape)\n",
    "    print('[hls4ml]', key, hls4ml_trace[key][0].flatten()[:N_ELEMENTS])\n",
    "    print('[keras] ', key, keras_trace[key][0].flatten()[:N_ELEMENTS])\n",
    "\n",
    "# Restore print options\n",
    "np.set_printoptions(threshold=bkp_threshold, linewidth=bkp_linewidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ef0d7-7af8-42fd-848f-afe57892d279",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Plot correlation qkeras and hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc91078-5827-4ae8-a95e-d4208078051a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate correlation plots\n",
    "for layer in hls4ml_trace.keys():\n",
    "    print(layer)\n",
    "    if '_alpha' in layer:\n",
    "        continue\n",
    "    plt.figure()\n",
    "    klayer = layer\n",
    "    if '_linear' in layer:\n",
    "        klayer = layer.replace('_linear', '')\n",
    "    plt.scatter(hls4ml_trace[layer].flatten(), keras_trace[klayer].flatten(), s=0.2)\n",
    "    min_x = min(np.amin(hls4ml_trace[layer]), np.amin(keras_trace[klayer]))\n",
    "    max_x = max(np.amax(hls4ml_trace[layer]), np.amax(keras_trace[klayer]))\n",
    "    plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "    plt.xlabel('hls4ml {}'.format(layer))\n",
    "    plt.ylabel('QKeras {}'.format(klayer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80211740-ee83-4832-a895-5464572a82de",
   "metadata": {},
   "source": [
    "## Run HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bab1a5-ea6b-4cc5-a7bb-0fd5c5070899",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_model(keras_model,\n",
    "                  hls_backend='Vivado',\n",
    "                  io_type='io_stream',\n",
    "                  conv_implementation='LineBuffer',\n",
    "                  fpga_part='xcu250-figd2104-2L-e',\n",
    "                  output_dir='hls4ml_vivado_{}_{}_{}_{}_prj'\n",
    "                 ):\n",
    "\n",
    "    yaml_config = hls4ml.backends.get_backend(hls_backend).create_initial_config(\n",
    "        part=fpga_part, \n",
    "        io_type=io_type,\n",
    "    )\n",
    "    # or whatever part you want to use\n",
    "    yaml_config['Backend'] = hls_backend\n",
    "\n",
    "    yaml_config['ProjectName'] = 'smartpixels'\n",
    "    config = hls4ml.utils.config_from_keras_model(keras_model, granularity='name', default_precision='fixed<16,3>')\n",
    "    config['LayerName']['input_1']['Precision']['result'] = 'fixed<4,1>'    \n",
    "    \n",
    "    # LineBuffer produces smaller implementations (Phil)\n",
    "    # Encoded    may produce larger implementations (Vladimir)\n",
    "    #            may be deprecated\n",
    "    config['Model']['ConvImplementation'] = conv_implementation\n",
    "    \n",
    "    yaml_config['HLSConfig'] = config\n",
    "\n",
    "    hls4ml.model.optimizer.get_optimizer('vivado:fifo_depth_optimization').configure(profiling_fifo_depth=100_000)\n",
    "    yaml_config['HLSConfig']['Flows'] = ['vivado:fifo_depth_optimization']\n",
    "\n",
    "    yaml_config['KerasModel'] = keras_model\n",
    "    yaml_config['OutputDir'] = output_dir.format(hls_backend.lower(), io_type.lower(), conv_implementation.lower(), fpga_part.lower())\n",
    "\n",
    "    # At this point you should verify that the yaml matches the one you already have (check the output directory of the existing project)\n",
    "\n",
    "    # About 10 samples should be enough, don't put a lot since you'll wait **A LOT** of time to simulate through them\n",
    "    x = quantized_bits(4, 0, alpha=1)(np.random.rand(10,13,21,20)).numpy() # or whatever the input is\n",
    "\n",
    "    from pathlib import Path\n",
    "    Path(yaml_config['OutputDir']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # We need both samples and predictions passed to the testbench for cosim to do meaningful stuff\n",
    "\n",
    "    input_data = ''\n",
    "    for sample in x:\n",
    "        for val in sample.flatten():\n",
    "            input_data += str(val) + ' '\n",
    "        input_data += '\\n'\n",
    "\n",
    "    input_data_path = yaml_config['OutputDir'] + '/input_data.dat'\n",
    "\n",
    "    with open(input_data_path, 'w') as f:\n",
    "        f.write(input_data.rstrip())\n",
    "    yaml_config['InputData'] = input_data_path\n",
    "\n",
    "    y = keras_model.predict(x)\n",
    "    output_data = ''\n",
    "    for prediction in y:\n",
    "        for val in prediction.flatten():\n",
    "            output_data += str(val) + ' '\n",
    "        output_data += '\\n'\n",
    "\n",
    "    output_data_path = yaml_config['OutputDir'] + '/output_data.dat'\n",
    "    with open(output_data_path, 'w') as f:\n",
    "        f.write(output_data.rstrip())\n",
    "    yaml_config['OutputPredictions'] = output_data_path\n",
    "\n",
    "    model = hls4ml.converters.keras_to_hls(yaml_config)\n",
    "    model.write()\n",
    "\n",
    "    # reset=True will nuke any existing synthesis, use with care\n",
    "    report = model.build(csim=False, synth=True, cosim=True, validation=False, export=True, vsynth=True, reset=True)\n",
    "    #report = model.build(csim=False, synth=False, cosim=False, validation=False, export=False, vsynth=False, reset=False)\n",
    "    report.pop('CSimResults', None) # We don't care about this, and it spams the output\n",
    "    report.pop('CosimResults', None)\n",
    "    print(report) # Print hashmap\n",
    "    return report, fpga_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33e1d8-e844-4f4f-8142-b4f2e727a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(cmd):\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    return result.stdout, result.stderr\n",
    "\n",
    "def print_report(report, fpga_part = '?', vivado_version = '?', hls = True, syn = True, cosim = True):\n",
    "    hls_results = report['CSynthesisReport']\n",
    "    syn_results = report['VivadoSynthReport']\n",
    "    cosim_results = report['CosimReport']\n",
    "    if hls:\n",
    "        print('-----------------------------------')\n",
    "        print('Vivado version: {}'.format(vivado_version))\n",
    "        print('FPGA part:      {}'.format(fpga_part))\n",
    "        print('-----------------------------------')\n",
    "        print('HLS')\n",
    "        print('Target Clock Period:    {} ns'.format(hls_results['TargetClockPeriod']))\n",
    "        print('Estimated Clock Period: {} ns'.format(hls_results['EstimatedClockPeriod']))\n",
    "        print('Best/Worst Latency: {} / {}'.format(hls_results['BestLatency'], hls_results['WorstLatency']))\n",
    "        print('Interval Min/Max:   {} / {}'.format(hls_results['IntervalMin'], hls_results['IntervalMax']))\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(hls_results['BRAM_18K'], float(hls_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(hls_results['DSP'], float(hls_results['DSP'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(hls_results['FF'], float(hls_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(hls_results['LUT'], float(hls_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "        #print(\"URAM:                   {}, {} (Aval. {})\".format(hls_results['URAM'], int(hls_results['URAM'])*100.0/int(hls_results['AvailableURAM']), hls_results['AvailableURAM']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Synthesis')\n",
    "        print('BRAM_18K:           {}, {:0.1f}% (Aval. {})'.format(syn_results['BRAM_18K'], float(syn_results['BRAM_18K'])*100.0/int(hls_results['AvailableBRAM_18K']), hls_results['AvailableBRAM_18K']))\n",
    "        print('DSP:                {}, {:0.1f}% (Aval. {})'.format(syn_results['DSP48E'], float(syn_results['DSP48E'])*100.0/int(hls_results['AvailableDSP']), hls_results['AvailableDSP']))\n",
    "        print('FF:                 {}, {:0.1f}% (Aval. {})'.format(syn_results['FF'], float(syn_results['FF'])*100.0/int(hls_results['AvailableFF']), hls_results['AvailableFF']))\n",
    "        print('LUT:                {}, {:0.1f}% (Aval. {})'.format(syn_results['LUT'], float(syn_results['LUT'])*100.0/int(hls_results['AvailableLUT']), hls_results['AvailableLUT']))\n",
    "    if syn:\n",
    "        print('-----------------------------------')\n",
    "        print('Cosimulation')\n",
    "        print('Max/Min Latency:    {} / {}'.format(cosim_results['LatencyMax'], cosim_results['LatencyMin']))\n",
    "        print('Avg Latency:        {}'.format(cosim_results['LatencyAvg']))\n",
    "        print('Max/Min Interval:   {} / {}'.format(cosim_results['IntervalMax'], cosim_results['IntervalMin']))\n",
    "        print('Avg Interval:       {}'.format(cosim_results['IntervalAvg']))\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140d76-3822-4e9e-8061-e267190ab84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = run_command('vivado -version')\n",
    "vivado_version = stdout.split()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a778a4-e6de-4b0d-ab9a-5bbf25adfc2c",
   "metadata": {},
   "source": [
    "### Alveo U250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ed15c-ea53-4394-b26b-e2c8da162d23",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "if (RUN_HLS):\n",
    "    report, fpga_part = convert_model(model,                                    \n",
    "                                      hls_backend='Vivado',\n",
    "                                      io_type='io_stream',\n",
    "                                      conv_implementation='LineBuffer',\n",
    "                                      #conv_implementation='Encoded',\n",
    "                                      fpga_part='xcu250-figd2104-2L-e',\n",
    "                                      output_dir='noslice_hls4ml_{}_{}_{}_{}_prj'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b15ed1-b187-41a0-8b48-25f7397cd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RUN_HLS):\n",
    "    print_report(report,\n",
    "                 fpga_part='xcu250-figd2104-2L-e',\n",
    "                 vivado_version=vivado_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c46d0-20e4-4443-8925-1fb5f7117c46",
   "metadata": {},
   "source": [
    "#### Previous results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0256dbb2-53f2-4f5b-bbc7-ef3c9dc20abb",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Implementation: LineBuffer\n",
    "IOType:         io_stream\n",
    "Strategy:       Latency\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.357 ns\n",
    "Best/Worst Latency: 277 / 277\n",
    "Interval Min/Max:   276 / 276\n",
    "BRAM_18K:           25, 0.5% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 13208, 0.4% (Aval. 3456000)\n",
    "LUT:                103010, 6.0% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           12.5, 0.2% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 10294, 0.3% (Aval. 3456000)\n",
    "LUT:                50856, 2.9% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    291 / 291\n",
    "Avg Latency:        291.0\n",
    "Max/Min Interval:   276 / 276\n",
    "Avg Interval:       276.0\n",
    "-----------------------------------\n",
    "Total time:         45min 3s\n",
    "-----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xcu250-figd2104-2L-e\n",
    "Implementation: Encoded\n",
    "IOType:         io_stream\n",
    "Strategy:       Latency\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.348 ns\n",
    "Best/Worst Latency: 279 / 279\n",
    "Interval Min/Max:   278 / 278\n",
    "BRAM_18K:           25, 0.5% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 35128, 1.0% (Aval. 3456000)\n",
    "LUT:                122342, 7.1% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           12.5, 0.2% (Aval. 5376)\n",
    "DSP:                0, 0.0% (Aval. 12288)\n",
    "FF:                 11891, 0.3% (Aval. 3456000)\n",
    "LUT:                55547, 3.2% (Aval. 1728000)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    295 / 295\n",
    "Avg Latency:        295.0\n",
    "Max/Min Interval:   278 / 278\n",
    "Avg Interval:       278.0\n",
    "-----------------------------------\n",
    "Total time:         43min 8s\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403fac0-8052-4bf7-a892-8251df9c1b86",
   "metadata": {},
   "source": [
    "### PYNQ-Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db671222-8a7d-40f9-85a7-3071d9af7616",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "if (RUN_HLS):\n",
    "    report, fpga_part = convert_model(model,                                    \n",
    "                                      hls_backend='Vivado',\n",
    "                                      io_type='io_stream',\n",
    "                                      conv_implementation='LineBuffer',\n",
    "                                      #conv_implementation='Encoded',\n",
    "                                      fpga_part='xc7z020clg400-1',\n",
    "                                      output_dir='noslice_hls4ml_{}_{}_{}_{}_prj'\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb1852-7ff8-4e77-bae5-58ac5598485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (RUN_HLS):\n",
    "    print_report(report,\n",
    "                 fpga_part=\"xc7z020clg400-1\",\n",
    "                 vivado_version=vivado_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33941f8-4789-4259-a182-93d5e03a5f5d",
   "metadata": {},
   "source": [
    "#### Previous results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b40b7ef-49f4-4d3a-b6d0-90f85b21f3bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xc7z020clg400-1\n",
    "Implementation: LineBuffer\n",
    "IOType:         io_stream\n",
    "Strategy:       Latency\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 5.407 ns\n",
    "Best/Worst Latency: 362 / 362\n",
    "Interval Min/Max:   311 / 311\n",
    "BRAM_18K:           25, 8.9% (Aval. 280)\n",
    "DSP:                0, 0.0% (Aval. 220)\n",
    "FF:                 75093, 70.6% (Aval. 106400)\n",
    "LUT:                120497, 226.5% (Aval. 53200)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           12.5, 4.5% (Aval. 280)\n",
    "DSP:                65, 29.5% (Aval. 220)\n",
    "FF:                 57287, 53.8% (Aval. 106400)\n",
    "LUT:                53639, 100.8% (Aval. 53200)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    759 / 453\n",
    "Avg Latency:        606.0\n",
    "Max/Min Interval:   277 / 277\n",
    "Avg Interval:       277.0\n",
    "-----------------------------------\n",
    "Total time:         45min 23s\n",
    "-----------------------------------\n",
    "\n",
    "\n",
    "\n",
    "-----------------------------------\n",
    "Vivado version: v2019.1\n",
    "FPGA part:      xc7z020clg400-1\n",
    "Implementation: Encoded\n",
    "IOType:         io_stream\n",
    "Strategy:       Latency\n",
    "-----------------------------------\n",
    "HLS\n",
    "Target Clock Period:    5.00 ns\n",
    "Estimated Clock Period: 4.375 ns\n",
    "Best/Worst Latency: 288 / 288\n",
    "Interval Min/Max:   283 / 283\n",
    "BRAM_18K:           25, 8.9% (Aval. 280)\n",
    "DSP:                0, 0.0% (Aval. 220)\n",
    "FF:                 75112, 70.6% (Aval. 106400)\n",
    "LUT:                127384, 239.4% (Aval. 53200)\n",
    "-----------------------------------\n",
    "Synthesis\n",
    "BRAM_18K:           12.5, 4.5% (Aval. 280)\n",
    "DSP:                65, 29.5% (Aval. 220)\n",
    "FF:                 59432, 55.9% (Aval. 106400)\n",
    "LUT:                58394, 109.8% (Aval. 53200)\n",
    "-----------------------------------\n",
    "Cosimulation\n",
    "Max/Min Latency:    636 / 363\n",
    "Avg Latency:        499.49999999999994\n",
    "Max/Min Interval:   283 / 283\n",
    "Avg Interval:       283.0\n",
    "-----------------------------------\n",
    "Total time:         46min 49s\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127df0c-7b5a-4673-a316-03aa19f158ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miscGithubEnviro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
