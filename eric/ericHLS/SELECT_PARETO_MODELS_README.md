# Pareto Optimal Model Selection (Two-Tier with Redundancy)

## Overview

The `select_pareto_models.py` script identifies and visualizes **Pareto optimal models** from hyperparameter tuning results. These models represent the best trade-offs between model complexity and validation accuracy.

**NEW**: The script now performs **two-tier Pareto selection** for redundancy:
1. **Primary Pareto Front**: The optimal trade-off frontier
2. **Secondary Pareto Front**: Next-best alternatives for redundancy and backup

### What is Pareto Optimality?

A model is **Pareto optimal** if no other model exists that is:
- **More accurate** (higher validation accuracy) AND
- **Less complex** (fewer parameters/nodes)

In other words, to improve one objective (accuracy or complexity), you must sacrifice the other. These models form the **Pareto front** - the optimal frontier of solutions.

### Why Two-Tier Selection?

The secondary Pareto front provides:
- **Redundancy**: Backup models if primary models fail synthesis or deployment
- **Alternatives**: Similar performance with different architectural choices
- **Robustness**: More options for hardware constraints or optimization goals

## Features

- ✅ **Two-tier Pareto selection** (primary + secondary for redundancy)
- ✅ Automatic Pareto front detection
- ✅ Beautiful visualizations with all models + both Pareto tiers highlighted
- ✅ Support for both `parameters` and `nodes` as complexity metrics
- ✅ Saves Pareto models to separate CSV files (primary, secondary, combined)
- ✅ Optionally copies model H5 files
- ✅ **Plots saved in complexity_analysis directory** for easy access
- ✅ Works with output from `analyze_hyperparameter_complexity.py`
- ✅ Comprehensive statistics and model rankings for both tiers

## Requirements

```bash
pip install numpy pandas matplotlib
```

## Usage

### Basic Usage

Select Pareto optimal models based on parameters:

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_models/model2_pareto
```

### Select Based on Nodes Instead

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model3_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_models/model3_pareto \
    --complexity_metric nodes
```

### Analyze Both Metrics

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_models/model2_pareto_both \
    --complexity_metric both
```

### Plot Only (No File Copying)

Useful for quick analysis without copying model files:

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_analysis/model2 \
    --plot_only
```

### Filter by Minimum Accuracy

Exclude poorly performing models before Pareto selection:

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_models/model2_pareto \
    --min_accuracy 0.85
```

### Specify Model Files Location

If model H5 files are in a different directory:

```bash
python select_pareto_models.py \
    --input_dir ../complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir ../pareto_models/model2_pareto \
    --models_dir ../hyperparameter_tuning/model2_quantized_4w0i_hyperparameter_results
```

## Command-Line Arguments

| Argument | Type | Required | Description |
|----------|------|----------|-------------|
| `--input_dir` | str | Yes | Directory containing complexity analysis CSV files |
| `--output_dir` | str | Yes | Output directory for plots and results |
| `--complexity_metric` | str | No | Metric to use: `parameters`, `nodes`, or `both` (default: `parameters`) |
| `--models_dir` | str | No | Directory containing model H5 files (auto-detected if not specified) |
| `--plot_only` | flag | No | Only generate plots, don't copy model files |
| `--min_accuracy` | float | No | Minimum accuracy threshold to consider models |

## Input Files

The script expects CSV files generated by `analyze_hyperparameter_complexity.py`:

- `hyperparameter_detailed_results.csv` (preferred) or
- `hyperparameter_complexity_summary.csv`

### Required CSV Columns

- `trial_id`: Trial identifier
- `val_accuracy`: Validation accuracy
- `parameters`: Total parameter count (if using this metric)
- `nodes`: Total node count (if using this metric)

## Output Files

### File Locations

- **Plots**: Saved in `input_dir` (complexity_analysis directory)
- **CSV/JSON/H5**: Saved in `output_dir` (specified by user)

### Generated Files

```
input_dir/ (complexity_analysis folder)
├── pareto_front_parameters_combined.png # Two-tier visualization (parameters)
└── pareto_front_nodes_combined.png      # Two-tier visualization (nodes)

output_dir/
├── pareto_optimal_models_parameters_primary.csv   # Primary Pareto models
├── pareto_optimal_models_parameters_secondary.csv # Secondary Pareto models (redundancy)
├── pareto_optimal_models_parameters_combined.csv  # All Pareto models
├── pareto_optimal_models_parameters.json          # JSON with both tiers
├── pareto_optimal_models_nodes_primary.csv        # Primary (if using nodes)
├── pareto_optimal_models_nodes_secondary.csv      # Secondary (if using nodes)
├── pareto_optimal_models_nodes_combined.csv       # All (if using nodes)
├── pareto_optimal_models_nodes.json               # JSON (if using nodes)
└── model_trial_XXX.h5                             # Copied model files (if not --plot_only)
```

### Visualization Features

The generated plots show:
- **Gray points**: All models
- **Red diamonds**: Primary Pareto optimal models
- **Orange squares**: Secondary Pareto optimal models (redundancy)
- **Red dashed line**: Connecting primary Pareto front
- **Orange dotted line**: Connecting secondary Pareto front
- **Yellow labels**: Trial IDs for primary Pareto models
- **Light yellow labels**: Trial IDs for secondary Pareto models
- **Statistics box**: Model counts for both tiers
- **Legend**: Clear distinction between all/primary/secondary models

## Example Workflow

### 1. Run Hyperparameter Tuning

```bash
python run_quantized_hyperparam_tuning_model2_5.py
```

### 2. Analyze Complexity

```bash
python analyze_hyperparameter_complexity.py \
    hyperparameter_tuning/model2_5_quantized_4w0i_hyperparameter_search
```

### 3. Select Pareto Models

```bash
python ericHLS/select_pareto_models.py \
    --input_dir complexity_analysis/model2_5_quantized_4w0i_hyperparameter_search \
    --output_dir pareto_models/model2_5_pareto \
    --complexity_metric both
```

### 4. Review Results

Check the output directory for:
- Visualizations showing the Pareto front
- CSV files with Pareto model details
- Copied model H5 files ready for deployment/HLS

## Understanding the Results

### Statistics Output

```
PARETO OPTIMAL SELECTION STATISTICS
================================================================================

Complexity metric: parameters
Total models: 149
Pareto optimal models: 12 (8.1%)

All Models                     Pareto Optimal Models         
--------------------------------------------------------------------------------

Validation Accuracy:          
  Min:  0.8072               0.8788              
  Max:  0.9077               0.9077              
  Mean: 0.8928               0.9002              

Parameters:
  Min:  2889                 2889                
  Max:  15129                14585               
  Mean: 9407.9               6969.0
```

### Interpretation

- **12 Pareto models (8.1%)**: Only these 12 models out of 149 are on the optimal frontier
- **Accuracy range**: Pareto models span 0.8788 to 0.9077 (best overall)
- **Parameter range**: Pareto models range from 2,889 (smallest) to 14,585 parameters
- **Mean complexity**: Pareto models average 6,969 params vs 9,407 for all models

### Selecting the Final Model

Choose from Pareto models based on your constraints:

1. **Maximum Accuracy**: Choose the Pareto model with highest accuracy
   - Best performance, but higher complexity
   
2. **Minimum Complexity**: Choose the Pareto model with lowest complexity
   - Smallest model, but lower accuracy
   
3. **Balanced Trade-off**: Choose a middle Pareto model
   - Good balance between accuracy and complexity

## Example Results

### Model2 Quantized (4w0i) - Two-Tier Selection

**Primary Pareto Front** (12 models):
```
Trial ID     Accuracy     Parameters     
----------------------------------------
027          0.9077       14585          <- Best accuracy (primary)
140          0.9057       12409          
023          0.9057       10505          
108          0.9055       8601           
003          0.9043       8329           
087          0.9033       6153           
032          0.9023       5881           
110          0.9021       3977           <- Balanced
064          0.9014       3705           
081          0.8989       3433           
144          0.8866       3161           
071          0.8788       2889           <- Smallest (primary)
```

**Secondary Pareto Front** (12 models - redundancy):
```
Trial ID     Accuracy     Parameters     
----------------------------------------
134          0.9067       14585          <- Backup for best accuracy
118          0.9057       12409          
068          0.9054       10505          
092          0.9033       8329           
042          0.9033       8057           
022          0.9018       7785           
026          0.9017       6153           
116          0.9002       5609           
079          0.8980       3705           
070          0.8948       3433           
104          0.8828       3161           
072          0.8754       2889           <- Backup for smallest
```

**Total selected**: 24 models (16.1% of 149)

### Model3 Quantized (4w0i)

```
Trial ID     Accuracy     Parameters     
----------------------------------------
012          0.9480       366473         <- Best accuracy
010          0.9479       302487         
004          0.9470       158327         <- Balanced
001          0.9447       79445          
003          0.9389       51467          <- Smallest
```

## Integration with HLS Workflow

After selecting Pareto models, you can proceed with HLS synthesis:

```bash
# 1. Select Pareto models
python ericHLS/select_pareto_models.py \
    --input_dir complexity_analysis/model2_quantized_4w0i_hyperparameter_search \
    --output_dir pareto_models/model2_pareto

# 2. Run HLS synthesis on Pareto models
python ericHLS/parallel_hls_synthesis.py \
    --input_dir pareto_models/model2_pareto \
    --num_workers 4

# 3. Analyze HLS results
python ericHLS/analyze_synthesis_results.py \
    --results_dir hls_results/model2_pareto

# 4. Plot and select final model
python ericHLS/plot_and_select_models.py \
    --results_dir hls_results/model2_pareto \
    --max_latency 100 \
    --max_resources 5000
```

## Troubleshooting

### No CSV files found

**Error**: `No complexity CSV file found`

**Solution**: Run `analyze_hyperparameter_complexity.py` first on your hyperparameter search directory.

### No Pareto models found

**Error**: `No Pareto optimal models found`

**Cause**: This can happen if:
- There's only one model in the dataset
- All models are dominated by a single best model

**Solution**: Check your input data and ensure you have multiple models with varying complexity and accuracy.

### Model files not copied

**Warning**: `Model file not found for trial XXX`

**Solution**: 
1. Check that model H5 files exist in the expected location
2. Specify `--models_dir` explicitly
3. Use `--plot_only` if you only need visualizations

## References

- **Pareto Efficiency**: https://en.wikipedia.org/wiki/Pareto_efficiency
- **Multi-objective Optimization**: https://en.wikipedia.org/wiki/Multi-objective_optimization

## Author

Eric - 2025

## See Also

- `analyze_hyperparameter_complexity.py`: Generates input data for this script
- `select_top_models.py`: Alternative selection method (percentile-based)
- `parallel_hls_synthesis.py`: Next step after model selection

